![CI](https://github.com/Aymane170/FakeSchoolData/actions/workflows/run_analysis.yml/badge.svg)


# **FakeSchoolData**

A fully automated data pipeline that simulates school data, loads it into Snowflake, transforms it using dbt (Silver & Gold models), and generates visual insights with Python â€” all scheduled daily via GitHub Actions.



## ğŸ¯ **Project Overview**

FakeSchoolData is a personal data engineering project designed to simulate, transform, and analyze fictional academic data. It covers the entire data lifecycle: data generation, ingestion, transformation, visualization, and automation.

This project demonstrates the use of a modern data stack in a complete end-to-end scenario.



## ğŸ§° **Tech Stack**

- **Languages**: Python 3.10, SQL  
- **Python Libraries**: `pandas`, `numpy`, `matplotlib`, `faker`, `snowflake-connector-python`  
- **Data Warehouse**: Snowflake  
- **Transformation Tool**: dbt (Data Build Tool)  
- **CI/CD**: GitHub Actions  
- **Visualization & Automation**: Python + matplotlib  
- **Version Control**: Git



## ğŸ“ **Repository Structure**


        FakeSchoolData/
        â”œâ”€â”€ .github/
        â”‚   â””â”€â”€ workflows/
        â”‚       â””â”€â”€ run_analysis.yml          # GitHub Actions CI/CD workflow (automated analysis)
        â”œâ”€â”€ generate_data.py                  # Script to generate fake school data
        â”œâ”€â”€ generate_gold_graphs.py           # Script to generate charts from Gold dbt models
        â”œâ”€â”€ charts/                          # Folder for auto-generated PNG charts
        â”œâ”€â”€ fakeschool_dbt/                  # dbt project for data transformations
        â”‚   â”œâ”€â”€ dbt_project.yml              # dbt project configuration file
        â”‚   â”œâ”€â”€ seeds/                      
        â”‚   â”‚   â”œâ”€â”€ students.csv             # Seed data: students
        â”‚   â”‚   â”œâ”€â”€ courses.csv              # Seed data: courses
        â”‚   â”‚   â””â”€â”€ results.csv              # Seed data: student results
        â”‚   â””â”€â”€ models/
        â”‚       â”œâ”€â”€ silver/                  # Silver layer models (cleaned/raw data)
        â”‚       â”‚   â”œâ”€â”€ dim_courses.sql      # Dimension table for courses
        â”‚       â”‚   â”œâ”€â”€ dim_students.sql     # Dimension table for students
        â”‚       â”‚   â”œâ”€â”€ fact_results.sql     # Fact table for results/grades
        â”‚       â”‚   â”œâ”€â”€ results_cleaned.sql  # Cleaned results data
        â”‚       â”‚   â””â”€â”€ schema.yml           # Documentation & tests for silver models
        â”‚       â””â”€â”€ gold/                    # Gold layer models (aggregated & analytic)
        â”‚           â”œâ”€â”€ avg_grade_per_course.sql               # Average grades by course
        â”‚           â”œâ”€â”€ avg_grade_per_students.sql             # Average grades by student
        â”‚           â”œâ”€â”€ top_student_per_course.sql             # Top student per course
        â”‚           â””â”€â”€ course_with_highest_failure_rate.sql  # Courses with highest failure rates
        â”œâ”€â”€ .gitignore                      # Git ignore rules



## ğŸ” **Workflow Summary**

### 1. **Data Generation â€“ `generate_data.py`**

This script uses Faker, Numpy, and Pandas to create realistic datasets:

- **Students**: 100 (ID, first name, last name)  
- **Courses**: 10 (ID, name)  
- **Results**: Random grades (0 to 20) for each student-course pair

**Output**:  
CSV files saved to `fakeschool_dbt/seeds/`  
(`students.csv`, `courses.csv`, `results.csv`)



### 2. **Load into Snowflake**

- Connects to Snowflake using `snowflake-connector-python`  
- Loads CSV data via `dbt seed`  
- Creates RAW tables (staging layer)  
- Prepares for dbt transformation



### 3. **Data Transformation with dbt**

The `fakeschool_dbt` project is structured into two layers:

#### ğŸ§ª **Silver (Cleaning & Structuring)**

- `dim_students.sql`: Student dimension table  
- `dim_courses.sql`: Course dimension table  
- `fact_results.sql`: Results fact table  
- `results_cleaned.sql`: Initial data cleanup  
- `schema.yml`: Model documentation and automated tests

#### ğŸ“Š **Gold (Business-Ready Analytics)**

- `avg_grade_per_course.sql`: Average grade by course  
- `avg_grade_per_students.sql`: Average grade by student  
- `top_student_per_course.sql`: Top student per course  
- `course_with_highest_failure_rate.sql`: Courses with the highest failure rates



### 4. **Visualization â€“ `generate_gold_graphs.py`**

This script queries the Gold models from Snowflake and generates charts using pandas and matplotlib:

- Grade distributions (histograms)  
- Averages per course/student  
- Failure rates  
- Top performers

**Charts are saved to the `charts/` directory.**



### 5. **Automation â€“ GitHub Actions**

- **Workflow file**: `.github/workflows/run_analysis.yml`  
- **Triggers**:
  - On every push to `main`
  - Daily at `08:00 UTC` via cron

**Steps executed automatically:**

1. Install Python and dependencies  
2. Inject Snowflake credentials via GitHub Secrets  
3. Run `generate_gold_graphs.py`  
4. Generate updated charts  
5. Store charts in `charts/` or as GitHub Artifacts



## ğŸ“Š **Sample Charts**

Charts are refreshed daily and may include:

- Grade distribution per course  
- Top students by average  
- Courses with highest failure rates  
- Average scores by student



## ğŸ‘¨â€ğŸ’» **Author**

**Aymane RAMI**  
*Data & Software Engineering Enthusiast*
